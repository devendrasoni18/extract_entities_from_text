{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('China', 'LOCATION'), ('15th June 2018', 'DATE'), ('2016', 'DATE'), ('Sunday', 'DATE'), ('New York Times', 'ORGANIZATION'), ('Apple', 'ORGANIZATION'), ('Samsung', 'ORGANIZATION'), ('Times', 'ORGANIZATION'), ('2013', 'DATE'), ('Tuesday', 'DATE'), ('Washington', 'LOCATION'), ('Lenovo', 'ORGANIZATION'), ('TCL', 'ORGANIZATION'), ('Apple', 'ORGANIZATION'), ('Samsung', 'ORGANIZATION'), ('Amazon', 'LOCATION'), ('US', 'LOCATION'), ('USA', 'ORGANIZATION'), ('U.S', 'LOCATION'), ('House Intelligence Committee', 'ORGANIZATION'), ('Huawei Technologies', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognization using Stanford pre-trained NER model of class 7\n",
    "# cd /home/NLP/\n",
    "# wget http://nlp.stanford.edu/software/stanford-ner-2015-04-20\n",
    "# unzip stanford-ner-2015-04-20.zip\n",
    "import nltk.tag.stanford as st\n",
    "import os\n",
    "\n",
    "# os.environ[\"CLASSPATH\"] = '/home/devendra/NLP/stanford-corenlp-full-2018-02-27'\n",
    "def space_out_punctuation(text):\n",
    "    text = re.sub(r',\\s', ' , ', text)\n",
    "    text = re.sub(r'\\.\\.\\.\\s', ' ... ', text)\n",
    "    text = re.sub(r'\\.\\s', ' . ', text)\n",
    "    text = re.sub(r';\\s', ' ; ', text)\n",
    "    text = re.sub(r':\\s', ' : ', text)\n",
    "    text = re.sub(r'\\?\\s', ' ? ', text)\n",
    "    text = re.sub(r'!\\s', ' ! ', text)\n",
    "    text = re.sub(r'\"', ' \" ', text)\n",
    "    text = re.sub(r'\\'', ' \\' ', text)\n",
    "    text = re.sub(r'\\â€™', ' \\' ', text)\n",
    "    text = re.sub(r'\\s\\(', ' ( ', text)\n",
    "    text = re.sub(r'\\)\\s', ' ) ', text)\n",
    "    text = re.sub(r'\\s\\[', ' [ ', text)\n",
    "    text = re.sub(r'\\]\\s', ' ] ', text)\n",
    "    text = re.sub(r'-', ' - ', text)\n",
    "    text = re.sub(r'_', ' _ ', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\r', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_continuous_chunks(tagged_sent):\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for token, tag in tagged_sent:\n",
    "        if tag != \"O\":\n",
    "            current_chunk.append((token, tag))\n",
    "        else:\n",
    "            if current_chunk: # if the current chunk is not empty\n",
    "                continuous_chunk.append(current_chunk)\n",
    "                current_chunk = []\n",
    "    # Flush the final current_chunk into the continuous_chunk, if any.\n",
    "    if current_chunk:\n",
    "        continuous_chunk.append(current_chunk)\n",
    "    return continuous_chunk\n",
    "\n",
    "# Initialize stanford tagger model \n",
    "stner = st.StanfordNERTagger('/home/NLP/stanford-ner-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "                             '/home/NLP/stanford-ner-2015-04-20/stanford-ner.jar')\n",
    "\n",
    "with open('data/extract_entities.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    text = space_out_punctuation(text)\n",
    "    tagged_sent = stner.tag(text.split())\n",
    "\n",
    "    named_entities = get_continuous_chunks(tagged_sent)\n",
    "    named_entities_str_tag = [(\" \".join([token for token, tag in ne]), ne[0][1]) for ne in named_entities]\n",
    "    print(named_entities_str_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
